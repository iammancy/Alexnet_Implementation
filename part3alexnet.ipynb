{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nfrom PIL import Image\nimport torch\nfrom torchvision import datasets\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader, random_split\nimport torchvision.transforms as transforms\nfrom torchvision.datasets import ImageFolder\nimport matplotlib.pyplot as plt\nimport torchvision.datasets as datasets\n\nimport torch.nn as nn\nimport torch.optim as optim\n\nimport torch\nfrom torchvision import transforms\nfrom torchvision.datasets import SVHN","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-11T06:24:21.485906Z","iopub.execute_input":"2023-04-11T06:24:21.486976Z","iopub.status.idle":"2023-04-11T06:24:25.191829Z","shell.execute_reply.started":"2023-04-11T06:24:21.486918Z","shell.execute_reply":"2023-04-11T06:24:25.190318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_normalize = [0.491, 0.482, 0.456]\nstd_dev_normalize = [0.229, 0.224, 0.225]\ncrop_size= 224\ndata_transform = transforms.Compose([\n        transforms.RandomResizedCrop(crop_size),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize(mean_normalize,std_dev_normalize )\n])","metadata":{"execution":{"iopub.status.busy":"2023-04-11T06:24:25.194259Z","iopub.execute_input":"2023-04-11T06:24:25.194866Z","iopub.status.idle":"2023-04-11T06:24:25.203925Z","shell.execute_reply.started":"2023-04-11T06:24:25.194822Z","shell.execute_reply":"2023-04-11T06:24:25.202793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_dataset = ImageFolder('/kaggle/input/cnn-dataset', \n                          transform=data_transform)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-11T06:24:25.205898Z","iopub.execute_input":"2023-04-11T06:24:25.207012Z","iopub.status.idle":"2023-04-11T06:24:36.628638Z","shell.execute_reply.started":"2023-04-11T06:24:25.206965Z","shell.execute_reply":"2023-04-11T06:24:36.627278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_split_ratio = 0.8\nimg_set_size = len(img_dataset)\ntrain_ratio = int(img_set_size * data_split_ratio)\ntest_ratio = int(img_set_size - train_ratio)\ntrain_data, test_data = torch.utils.data.random_split(img_dataset,\n                                                      [train_ratio, test_ratio])\nbatch_size = 64\ntrain_img_loader = torch.utils.data.DataLoader(train_data, \n                                               batch_size=batch_size,\n                                               shuffle=True)\ntest_img_loader = torch.utils.data.DataLoader(test_data, \n                                              batch_size=batch_size, \n                                              shuffle=False)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-04-11T06:24:36.631444Z","iopub.execute_input":"2023-04-11T06:24:36.631916Z","iopub.status.idle":"2023-04-11T06:24:36.664584Z","shell.execute_reply.started":"2023-04-11T06:24:36.631867Z","shell.execute_reply":"2023-04-11T06:24:36.663655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##some sample train images\nclass_labels = (1, 2, 0)\nfor idx, batch in enumerate(train_img_loader):\n    fig, axs = plt.subplots(1, 5, figsize=(10, 5))\n    inputs = batch[0]\n    labels = batch[1]\n    for j in range(0,5):\n        axs[j].imshow(inputs[j].permute(class_labels)),axs[j].axis('off'),axs[j].set_title(f'Label: {labels[j]}')\n    plt.show()\n    break\n","metadata":{"execution":{"iopub.status.busy":"2023-04-11T06:24:36.666102Z","iopub.execute_input":"2023-04-11T06:24:36.666470Z","iopub.status.idle":"2023-04-11T06:24:37.480163Z","shell.execute_reply.started":"2023-04-11T06:24:36.666433Z","shell.execute_reply":"2023-04-11T06:24:37.479140Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_labels = (1, 2, 0)\nfor idx, batch in enumerate(test_img_loader): ##similarly lets checkout some test samples\n    fig, axs = plt.subplots(1, 5, figsize=(10, 5))\n    inputs = batch[0]\n    labels = batch[1]\n    for j in range(0,5):\n        axs[j].imshow(inputs[j].permute(class_labels)),axs[j].axis('off'),axs[j].set_title(f'Label: {labels[j]}')\n    plt.show()\n    break\n    ","metadata":{"execution":{"iopub.status.busy":"2023-04-11T06:24:37.481332Z","iopub.execute_input":"2023-04-11T06:24:37.481702Z","iopub.status.idle":"2023-04-11T06:24:38.054371Z","shell.execute_reply.started":"2023-04-11T06:24:37.481665Z","shell.execute_reply":"2023-04-11T06:24:38.053291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AlexNet(nn.Module):\n    def __init__(self, num_classes=3):\n        super(AlexNet, self).__init__()\n        self.num_classes = num_classes\n        self.localnorm = nn.LocalResponseNorm(size=5)\n        self.layer1 = nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=0)\n        self.activation_layer_relu = nn.ReLU(inplace=True)\n        self.max_pool_layer = nn.MaxPool2d(kernel_size=3, stride=2)\n        self.layer2 = nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2)\n        self.layer3 = nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1)\n        self.layer4 = nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=1)\n        self.layer5 = nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1)\n        self.layer6 = nn.MaxPool2d(kernel_size=3, stride=2)\n        self.dropuput_layer = nn.Dropout(0.5)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n        self.fc1 = nn.Linear(256 * 6 * 6, 4096)\n        self.fc2 = nn.Linear(4096, 4096)\n        self.fc3 = nn.Linear(4096, num_classes)\n\n        # initialize weights\n        self.apply(self.initialize_weights)\n\n    def forward(self, x):\n        # move tensors to CUDA device\n        x = x.cuda()\n        out = self.layer1(x)\n        out = self.activation_layer_relu(out)\n        out = self.localnorm(out)\n        out = self.max_pool_layer(out)\n        out = self.layer2(out)\n        out = self.activation_layer_relu(out)\n        out = self.localnorm(out)\n        out = self.max_pool_layer(out)\n        out = self.layer3(out)\n        out = self.activation_layer_relu(out)\n        out = self.layer4(out)\n        out = self.activation_layer_relu(out)\n        out = self.layer5(out)\n        out = self.activation_layer_relu(out)\n        out = self.layer6(out)\n        out = self.avgpool(out)\n        out = torch.flatten(out, 1)\n        out = self.fc1(out)\n        out = self.activation_layer_relu(out)\n        out = self.dropuput_layer(out)\n        out = self.fc2(out)\n        out = self.activation_layer_relu(out)\n        out = self.dropuput_layer(out)\n        out = self.fc3(out)\n        return out\n\n    def initialize_weights(self, m):\n        if isinstance(m, nn.Conv2d):\n            nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n            if m.bias is not None:\n                nn.init.constant_(m.bias, 0)\n        elif isinstance(m, nn.BatchNorm2d):\n            nn.init.constant_(m.weight, 1)\n            nn.init.constant_(m.bias, 0)\n        elif isinstance(m, nn.Linear):\n            nn.init.normal_(m.weight, 0, 0.01)\n            nn.init.constant_(m.bias, 0)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-11T06:24:38.056288Z","iopub.execute_input":"2023-04-11T06:24:38.056667Z","iopub.status.idle":"2023-04-11T06:24:38.073938Z","shell.execute_reply.started":"2023-04-11T06:24:38.056625Z","shell.execute_reply":"2023-04-11T06:24:38.072807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(\"Availabe device: \", device)","metadata":{"execution":{"iopub.status.busy":"2023-04-11T06:24:59.316352Z","iopub.execute_input":"2023-04-11T06:24:59.316739Z","iopub.status.idle":"2023-04-11T06:24:59.424564Z","shell.execute_reply.started":"2023-04-11T06:24:59.316692Z","shell.execute_reply":"2023-04-11T06:24:59.422021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learning_rate = 0.001\nmomentum_val = 0.9\nmodel = AlexNet().to(device)\noptimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum_val)\ncriterion = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2023-04-11T06:25:12.015127Z","iopub.execute_input":"2023-04-11T06:25:12.015516Z","iopub.status.idle":"2023-04-11T06:25:15.924389Z","shell.execute_reply.started":"2023-04-11T06:25:12.015472Z","shell.execute_reply":"2023-04-11T06:25:15.923285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(0,50):\n    train_loss, train_correct, total_train = 0.0, 0, 0\n\n    model.train()\n    for i, batch in enumerate(train_img_loader):\n        ip, labl = batch\n        optimizer.zero_grad()\n        ip, labl = ip.to(\"cuda\"), labl.to(\"cuda\")  ## move the data to GPU\n        outputs = model(ip)\n        loss = criterion(outputs, labl)\n         \n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item()\n        opt, y_hat = torch.max(outputs.data, 1)\n        total_correct_val = (y_hat == labl)\n        train_correct += total_correct_val.sum().item()\n        total_train += labl.size(0)\n\n    test_loss, test_correct, test_total = 0.0, 0, 0\n\n    model.eval()\n\n    with torch.no_grad():\n        for i, batch in enumerate(test_img_loader):\n            ip, labl = batch\n            ip, labl = ip.to(\"cuda\"), labl.to(\"cuda\")  ## move the data to GPU\n            outputs = model(ip)\n            loss = criterion(outputs, labl)\n            \n            opt, y_hat = torch.max(outputs.data, 1)\n            total_correct_val_y = (y_hat == labl)\n            test_correct += total_correct_val_y.sum().item()\n            test_total += labl.size(0)\n            test_loss += loss.item()\n    \n    train_accuracy = 100 * train_correct / total_train\n    train_loss /= len(train_img_loader)\n    test_accuracy = 100 * test_correct / test_total\n    test_loss /= len(test_img_loader)\n\n    # Print training and test accuracy and loss for each epoch\n    print(f'Currently running {epoch+1} epoch current train Loss: {train_loss:.5f} Current train Accuracy: {train_accuracy:.2f}% Our Test loss  {test_loss:.5f} And our test Accuracy: {test_accuracy:.2f}%')\n","metadata":{"execution":{"iopub.status.busy":"2023-04-11T06:50:41.296878Z","iopub.execute_input":"2023-04-11T06:50:41.297591Z","iopub.status.idle":"2023-04-11T08:35:07.240506Z","shell.execute_reply.started":"2023-04-11T06:50:41.297551Z","shell.execute_reply":"2023-04-11T08:35:07.239284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}